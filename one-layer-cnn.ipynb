{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\codes\\cnn\\.venv\\lib\\site-packages (1.26.4)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: matplotlib in d:\\codes\\cnn\\.venv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-learn in d:\\codes\\cnn\\.venv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: pillow in d:\\codes\\cnn\\.venv\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\codes\\cnn\\.venv\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\codes\\cnn\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\codes\\cnn\\.venv\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\codes\\cnn\\.venv\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\codes\\cnn\\.venv\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\codes\\cnn\\.venv\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\codes\\cnn\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\codes\\cnn\\.venv\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\codes\\cnn\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\codes\\cnn\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\codes\\cnn\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy matplotlib scikit-learn pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas necessárias\n",
    "import numpy as np  # Biblioteca para cálculos matemáticos\n",
    "import matplotlib.pyplot as plt  # Biblioteca para visualização de gráficos\n",
    "from sklearn.model_selection import train_test_split  # Função para dividir os dados em treino e teste\n",
    "from sklearn.preprocessing import LabelBinarizer  # Função para binarizar rótulos (Cat/Dog)\n",
    "from PIL import Image  # Biblioteca para carregar e processar imagens\n",
    "import os  # Biblioteca para interagir com o sistema de arquivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar o dataset com base nos diretórios 'Cat' e 'Dog'\n",
    "def load_data(path):\n",
    "    categories = ['Cat', 'Dog']  # As duas classes do dataset\n",
    "    file_paths = []  # Lista para armazenar os caminhos das imagens\n",
    "    labels = []  # Lista para armazenar os rótulos (0 para Cat, 1 para Dog)\n",
    "\n",
    "    # Iterando sobre as categorias\n",
    "    for category in categories:\n",
    "        folder = os.path.join(path, category)  # Caminho para a pasta 'Cat' ou 'Dog'\n",
    "        label = categories.index(category)  # Atribui 0 a 'Cat' e 1 a 'Dog'\n",
    "\n",
    "        # Itera sobre todos os arquivos da pasta\n",
    "        for filename in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, filename)  # Caminho completo da imagem\n",
    "            file_paths.append(file_path)  # Adiciona o caminho da imagem à lista\n",
    "            labels.append(label)  # Adiciona o rótulo correspondente\n",
    "\n",
    "    return np.array(file_paths), np.array(labels)  # Retorna os caminhos e rótulos como arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para pré-processar cada imagem\n",
    "def preprocess_image(image_path, target_size=(64, 64)):\n",
    "    img = Image.open(image_path).convert('L')  # Converte a imagem para escala de cinza\n",
    "    img = img.resize(target_size)  # Redimensiona a imagem para 64x64 pixels\n",
    "    img_array = np.array(img) / 255.0  # Normaliza os valores dos pixels (0 a 1)\n",
    "    return img_array.flatten()  # Retorna a imagem como um vetor unidimensional\n",
    "\n",
    "# Carregar o dataset de gatos e cães\n",
    "dataset_path = os.path.abspath('D:/Codes/cnn/dataset')  # Diretório contendo as pastas 'Cat' e 'Dog'\n",
    "file_paths, labels = load_data(dataset_path)  # Carrega as imagens e rótulos\n",
    "\n",
    "# Pré-processar todas as imagens (converter em arrays numéricos)\n",
    "X = np.array([preprocess_image(img_path) for img_path in file_paths])\n",
    "y = labels.reshape(-1, 1)  # Os rótulos (0 ou 1) são armazenados como uma matriz de uma coluna\n",
    "\n",
    "# Dividir o dataset em conjunto de treino (80%) e teste (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para inicializar os parâmetros da rede neural (pesos e bias)\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    np.random.seed(1)  # Garante a reprodutibilidade dos resultados\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01  # Inicializa os pesos da camada oculta com valores aleatórios\n",
    "    b1 = np.zeros((n_h, 1))  # Inicializa o bias da camada oculta como zeros\n",
    "    W2 = np.random.randn(n_y, n_h) * 0.01  # Inicializa os pesos da camada de saída\n",
    "    b2 = np.zeros((n_y, 1))  # Inicializa o bias da camada de saída como zeros\n",
    "    \n",
    "    # Armazena os parâmetros em um dicionário\n",
    "    parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
    "    return parameters  # Retorna os parâmetros\n",
    "\n",
    "# Definindo os tamanhos das camadas\n",
    "n_x = X_train.shape[1]  # Número de features (tamanho da imagem vetorizada)\n",
    "n_h = 4  # Neurônios na camada oculta (valor arbitrário)\n",
    "n_y = 1  # Número de saídas (1 para classificação binária)\n",
    "\n",
    "# Inicializa os parâmetros da rede\n",
    "parameters = initialize_parameters(n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de forward propagation (propagação para frente)\n",
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']  # Pesos da camada oculta\n",
    "    b1 = parameters['b1']  # Bias da camada oculta\n",
    "    W2 = parameters['W2']  # Pesos da camada de saída\n",
    "    b2 = parameters['b2']  # Bias da camada de saída\n",
    "    \n",
    "    # Cálculo do Z1 (entrada da função de ativação na camada oculta)\n",
    "    Z1 = np.dot(W1, X.T) + b1\n",
    "    A1 = np.tanh(Z1)  # Função de ativação (tangente hiperbólica) na camada oculta\n",
    "    Z2 = np.dot(W2, A1) + b2  # Cálculo do Z2 (entrada da função de ativação na camada de saída)\n",
    "    A2 = 1 / (1 + np.exp(-Z2))  # Função sigmoide na camada de saída (probabilidade entre 0 e 1)\n",
    "    \n",
    "    # Armazena os valores intermediários no cache para uso na backpropagation\n",
    "    cache = {\"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2}\n",
    "    return A2, cache  # Retorna a saída final e os valores intermediários\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular o custo (erro) da predição\n",
    "def compute_cost(A2, Y, parameters):\n",
    "    m = Y.shape[0]  # Número de exemplos no dataset\n",
    "    # Cálculo da função de custo (cross-entropy)\n",
    "    logprobs = Y.T * np.log(A2) + (1 - Y.T) * np.log(1 - A2)\n",
    "    cost = -np.sum(logprobs) / m  # Calcula a média do erro\n",
    "    cost = np.squeeze(cost)  # Garante que o custo seja um valor escalar\n",
    "    return cost  # Retorna o custo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para realizar a backward propagation (retropropagação)\n",
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    m = X.shape[0]  # Número de exemplos\n",
    "    \n",
    "    # Recupera os parâmetros\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    # Recupera os valores intermediários do cache\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "    \n",
    "    # Calcula o gradiente da função de custo em relação a Z2\n",
    "    dZ2 = A2 - Y.T\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T)  # Gradiente dos pesos W2\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)  # Gradiente do bias b2\n",
    "    \n",
    "    # Calcula o gradiente da função de custo em relação a Z1\n",
    "    dZ1 = np.dot(W2.T, dZ2) * (1 - np.power(A1, 2))  # Derivada da função tangente hiperbólica\n",
    "    dW1 = (1 / m) * np.dot(dZ1, X)  # Gradiente dos pesos W1\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)  # Gradiente do bias b1\n",
    "    \n",
    "    # Armazena os gradientes em um dicionário\n",
    "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "    return grads  # Retorna os gradientes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para atualizar os parâmetros usando o gradient descent\n",
    "def update_parameters(parameters, grads, learning_rate=0.01):\n",
    "    W1 = parameters['W1'] - learning_rate * grads['dW1']  # Atualiza W1\n",
    "    b1 = parameters['b1'] - learning_rate * grads['db1']  # Atualiza b1\n",
    "    W2 = parameters['W2'] - learning_rate * grads['dW2']  # Atualiza W2\n",
    "    b2 = parameters['b2'] - learning_rate * grads['db2']  # Atualiza b2\n",
    "    \n",
    "    # Armazena os parâmetros atualizados\n",
    "    parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
    "    return parameters  # Retorna os parâmetros atualizados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custo após a iteração 0: 0.6930949692375822\n",
      "Custo após a iteração 100: 0.6929159155264814\n",
      "Custo após a iteração 200: 0.6926644104598834\n",
      "Custo após a iteração 300: 0.6921732342999208\n",
      "Custo após a iteração 400: 0.6909937002906821\n",
      "Custo após a iteração 500: 0.688202832561125\n",
      "Custo após a iteração 600: 0.6823529851744597\n",
      "Custo após a iteração 700: 0.6717142002367913\n",
      "Custo após a iteração 800: 0.6548166460626551\n",
      "Custo após a iteração 900: 0.6301114718387674\n"
     ]
    }
   ],
   "source": [
    "# Função que realiza o treinamento da rede neural\n",
    "def train_model(X, Y, n_h, num_iterations=10000, learning_rate=0.1):\n",
    "    n_x = X.shape[1]  # Tamanho da camada de entrada\n",
    "    n_y = 1  # Número de unidades de saída (classificação binária)\n",
    "    \n",
    "    # Inicializa os parâmetros\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    \n",
    "    # Itera sobre o número de iterações desejado\n",
    "    for i in range(num_iterations):\n",
    "        A2, cache = forward_propagation(X, parameters)  # Executa a forward propagation\n",
    "        cost = compute_cost(A2, Y, parameters)  # Calcula o custo\n",
    "        grads = backward_propagation(parameters, cache, X, Y)  # Executa a backward propagation\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)  # Atualiza os parâmetros\n",
    "        \n",
    "        # A cada 100 iterações, imprime o custo\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Custo após a iteração {i}: {cost}\")\n",
    "    \n",
    "    return parameters  # Retorna os parâmetros treinados\n",
    "\n",
    "# Treina a rede neural com o conjunto de treinamento\n",
    "parameters = train_model(X_train, y_train, n_h=4, num_iterations=1000, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão do modelo no conjunto de teste: 49.55%\n"
     ]
    }
   ],
   "source": [
    "# Função para realizar a predição usando os parâmetros treinados\n",
    "def predict(X, parameters):\n",
    "    A2, _ = forward_propagation(X, parameters)  # Executa a forward propagation\n",
    "    predictions = (A2 > 0.5).astype(int)  # Classifica como 1 (Dog) se A2 > 0.5, senão 0 (Cat)\n",
    "    return predictions.T  # Retorna as predições\n",
    "\n",
    "# Realiza a predição no conjunto de teste\n",
    "y_pred = predict(X_test, parameters)\n",
    "\n",
    "# Calcula a precisão do modelo\n",
    "accuracy = np.mean(y_pred == y_test.T) * 100\n",
    "print(f\"Precisão do modelo no conjunto de teste: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
